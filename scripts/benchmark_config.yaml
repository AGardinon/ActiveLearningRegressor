# ------------------------------------------------------------------------------
# Benchmark configuration file for Active Learning Regressor experiments
# ------------------------------------------------------------------------------
SEED: 13

experiment_name: "6D/ackley_gpr_50cy_2pts_ei_refine"
experiment_notes: "Benchmarking the Ackley 6D function"

# --------------------------------------------------------------
# Ground truth data configuration
ground_truth_file: null #"ackley6d_lhs.csv"
ground_truth_parameters:
  function: "Ackley"
  n_dimensions: 6
  bounds:
    - [-32.768, 32.768]
    - [-32.768, 32.768]
    - [-32.768, 32.768]
    - [-32.768, 32.768]
    - [-32.768, 32.768]
    - [-32.768, 32.768]
  n_samples: 10000
  val_size: 1.0
  method: "lhs"
  negate: true
  noise_std: 0.0

search_space_variables:
  - "x1"
  - "x2"
  - "x3"
  - "x4"
  - "x5"
  - "x6"

target_variables:
  - "y"

# --------------------------------------------------------------
# Data scaling configuration
data_scaler: "StandardScaler"
scaler_params: null

# --------------------------------------------------------------
# Adaptive refinement configuration
adaptive_refinement:
  function: "Ackley"
  n_dimensions: 6
  bounds:
    - [-32.768, 32.768]
    - [-32.768, 32.768]
    - [-32.768, 32.768]
    - [-32.768, 32.768]
    - [-32.768, 32.768]
    - [-32.768, 32.768]
  method: 'lhs'
  negate: true
  refinement_noise_std: 0.0
  refinement_step: 20  # number of points acquired after which to perform refinement
  refinement_centroids: 3  # number of centroids to use for the refinement (chosen via fps)
  refinement_batch_size: 500  # number of points to sample around each centroid during refinement
  centroids_selection_method: "voronoi"  # "voronoi" or "fps" (farthest point sampling)

# --------------------------------------------------------------
# Cycles parameters
n_cycles: 50
init_batch_size: 2
init_sampling: "random"
cycle_sampling: "voronoi"

# --------------------------------------------------------------
# ML model configuration
ml_model: "GPR"

model_parameters:
  kernel_recipe: "MATERN_W"  # for GPR either "RBF_W" or "MATERN_W" or custom recipe
  n_restarts_optimizer: 300
  alpha: 1e-10
  normalize_y: true
  optimizer: 'fmin_l_bfgs_b'
  use_gridsearch: false
  log_transform: false

# --------------------------------------------------------------
# Acquisition functions configuration
acquisition_parameters:
  - acquisition_mode: "expected_improvement"
    percentile: 95

  - acquisition_mode: "target_expected_improvement_800"
    percentile: 95
    y_target: 800
    epsilon: 150

  - acquisition_mode: "maximum_predicted_value"
    percentile: 'Max'

  - acquisition_mode: "target_expected_improvement_1200"
    percentile: 95
    y_target: 1200
    epsilon: 150

  - acquisition_mode: "exploration_mutual_info"
    percentile: 95

  - acquisition_mode: "percentage_target_expected_improvement"
    percentile: 95
    percentage: 80

  - acquisition_mode: "random"
    percentile: 0

landscape_penalization: null  # radius: 0.25, strength: 1.0

# --------------------------------------------------------------
# Multi-stage acquisition protocol configuration
acquisition_protocol:
  stage_1:
    cycles: 50
    acquisition_modes: ['expected_improvement']
    n_points: [2]  # Number of points to acquire for each mode in stage 1
  # stage_2:
  #   cycles: 40
  #   acquisition_modes: ['expected_improvement']
  #   n_points: [2]  # Number of points to acquire for each mode in stage 2
  # stage_3:
  #   cycles: 10
  #   acquisition_modes: ['exploration_mutual_info']
  #   n_points: [2]  # Number of points to acquire for each mode in stage 3
  # stage_4:
  #   cycles: 20
  #   acquisition_modes: ['expected_improvement']
  #   n_points: [2]  # Number of points to acquire for each mode in stage 4

