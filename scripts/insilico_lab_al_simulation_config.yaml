# Experiment configuration for in-silico lab active learning simulation
experiment_name: "ackley3d_20cy_mi_tei_ei"
experiment_notes: "acqui_func.landscape_acquisition() with penalize landscape and predictiong only on candidates."
experiment_evidence:

search_space_variables:
  - "x1"
  - "x2"
  - "x3"

target_variables:
  - "y"

# Cycles parameters
init_batch_size: 5
n_cycles: 19

init_sampling: "voronoi"
cycle_sampling: "voronoi"

# ML model configuration (GPR)
# Kernel configuration for GPR
# either "RBF_W" or "MATERN_W" or custom recipe
ml_model: "GPR"
kernel_recipe: "MATERN_W"

# Additional paramters
model_parameters:
  n_restarts_optimizer: 300
  alpha: 1e-10
  normalize_y: true
  optimizer: 'fmin_l_bfgs_b'
  use_gridsearch: false
  log_transform: false

data_scaler: "StandardScaler"

# List of acquisition parameters functions to be used in the simulation
acquisition_parameters:
  - acquisition_mode: "expected_improvement"
    percentile: 90

  - acquisition_mode: "target_expected_improvement_800"
    percentile: 90
    y_target: 800
    epsilon: 150

  - acquisition_mode: "maximum_predicted_value"
    percentile: 'Max'

  - acquisition_mode: "target_expected_improvement_1200"
    percentile: 90
    y_target: 1200
    epsilon: 150

  - acquisition_mode: "exploration_mutual_info"
    percentile: 90

  - acquisition_mode: "percentage_target_expected_improvement"
    percentile: 90
    percentage: 80

landscape_penalization:
  # radius: 0.25
  # strength: 1.0

# Define stages with specific acquisition modes and cycle lengths 
acquisition_protocol:
  stage_1:
    cycles: 19
    acquisition_modes: ['exploration_mutual_info', 'percentage_target_expected_improvement', 'expected_improvement']
    n_points: [2, 1, 2]  # Number of points to acquire for each mode in stage 1

# Path to the ground truth file in the datasets directory
ground_truth_file: "ackley3d_10000pts.csv"
