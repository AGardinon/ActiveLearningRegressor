# Experiment configuration for in-silico lab active learning simulation
experiment_name: "3rep_6c_3pt_protocol_1"
experiment_notes: "acqui_func.landscape_acquisition() with penalize landscape and predictiong only on candidates."
experiment_evidence:

search_space_variables:
  - "x1"
  - "x2"

target_variables:
  - "Number_of_Particles"

# Cycles parameters
init_batch_size: 6
n_cycles: 6

init_sampling: "fps"
cycle_sampling: "voronoi"

# ML model configuration (GPR)
# Kernel configuration for GPR
# either "RBF_W" or "MATERN_W" or custom recipe
ml_model: "GPR"
kernel_recipe: "RBF_W"

# Additional paramters
model_parameters:
  n_restarts_optimizer: 300
  # alpha: 1e-10
  normalize_y: true
  optimizer: 'fmin_l_bfgs_b'
  use_gridsearch: false
  log_transform: false

data_scaler: "StandardScaler"

# List of acquisition parameters functions to be used in the simulation
acquisition_parameters:
  - acquisition_mode: "expected_improvement"
    percentile: 90
    n_points: 2

  - acquisition_mode: "target_expected_improvement"
    percentile: 90
    y_target: 800
    epsilon: 150
    n_points: 1

  - acquisition_mode: "exploration_mutual_info"
    percentile: 90
    n_points: 1

landscape_penalization:
  radius: 0.25
  strength: 1.0

# Define stages with specific acquisition modes and cycle lengths 
acquisition_protocol:
  stage_1:
    cycles: 3
    acquisition_modes: ['expected_improvement', 'exploration_mutual_info']
  stage_2:
    cycles: 3
    acquisition_modes: ['target_expected_improvement', 'expected_improvement']

# Path to the ground truth file in the datasets directory
ground_truth_file: "gt_number_of_particles_maternw.csv"
